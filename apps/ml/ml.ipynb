{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://joedavis29:WqrCpIQMKm74@ep-misty-frost-342565.us-east-2.aws.neon.tech/neondb?sslmode=require\n",
      "Down Up 87 87\n",
      "Down Up 78 78\n",
      "Down Up 72 72\n",
      "Down Up 84 84\n",
      "Down Up 72 72\n",
      "Down Up 96 96\n",
      "Down Up 78 78\n",
      "Down Up 96 96\n",
      "Square 134 134\n",
      "Square 129 129\n",
      "Square 119 119\n",
      "Square 125 125\n",
      "Square 171 171\n",
      "Circle 77 77\n",
      "Square 113 113\n",
      "Square 132 132\n",
      "Square 149 149\n",
      "Circle 95 95\n",
      "Circle 74 74\n",
      "Circle 72 72\n",
      "Circle 71 71\n",
      "Circle 72 72\n",
      "Circle 66 66\n",
      "Up Down 78 78\n",
      "Up Down 84 84\n",
      "Circle 105 105\n",
      "Circle 74 74\n",
      "Up Down 66 66\n",
      "Up Down 86 86\n",
      "Up Down 84 84\n",
      "Up Down 86 86\n",
      "Up Down 98 98\n",
      "Up Down 167 167\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import psycopg\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def get_connection():\n",
    "  DATABASE_URL = os.getenv('DATABASE_URL')\n",
    "  CONNECTION_DICT = psycopg.conninfo.conninfo_to_dict(DATABASE_URL)\n",
    "  conn = psycopg.connect(**CONNECTION_DICT)\n",
    "  return conn\n",
    "\n",
    "conn = get_connection()\n",
    "\n",
    "cur = conn.execute('Select * FROM \"Session\" LIMIT 0')\n",
    "colnames = [desc[0] for desc in cur.description]\n",
    "\n",
    "res = conn.execute('''\n",
    "  SELECT s.*, m.name as move_name FROM \"Session\" AS s\n",
    "  join \"Move\" as m on s.\"moveId\" = m.\"id\"\n",
    "  WHERE s.\"moveId\" IN (\n",
    "    'cllsr98nl0000m3wg0pqpvjuy',\n",
    "    'cllsr98nn0002m3wg3l6nbb5l',\n",
    "    'cllsr98nn0004m3wgcm0bpdta',\n",
    "    'cllsr98no0006m3wgbau6ed9q'\n",
    "  );\n",
    "''')\n",
    "\n",
    "sessions = res.fetchall()\n",
    "columns = [col[0] for col in res.description]\n",
    "sessions = [dict(zip(columns, session)) for session in sessions]\n",
    "\n",
    "sessions[:] = [i for i in sessions if len(i['accelerationX']) == len(i['gyroX'])]\n",
    "for s in sessions:\n",
    "  print(s['move_name'], len(s['gyroX']), len(s['accelerationX']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "data_columns = ['gyroX','gyroY','gyroZ','accelerationX','accelerationY','accelerationZ']\n",
    "\n",
    "def prep_sessions(sessions, data_columns):\n",
    "  #convert each session to a an array of just the data\n",
    "  dfs = []\n",
    "  for s in sessions:\n",
    "    df = pandas.DataFrame(s)[data_columns]\n",
    "    np_array = df.to_numpy().astype(float)\n",
    "    dfs.append(np_array)\n",
    "\n",
    "  return dfs\n",
    "\n",
    "def generate_labels_from_sessions(sessions):\n",
    "    names = [s['move_name'] for s in sessions]\n",
    "\n",
    "    labels_key = {}\n",
    "    labels = [labels_key.setdefault(n, len(labels_key)) for n in names]\n",
    "\n",
    "    return labels, labels_key\n",
    "\n",
    "def vertically_scale_array(original_array):\n",
    "  # scale it up vertically\n",
    "  original_shape = original_array.shape\n",
    "  target_shape = (200, original_shape[1])\n",
    "\n",
    "  # Generate indices for original and target arrays\n",
    "  original_indices = np.arange(original_shape[0])\n",
    "  target_indices = np.linspace(0, original_shape[0] - 1, target_shape[0])\n",
    "\n",
    "  scaled_up_array = np.empty(target_shape)\n",
    "\n",
    "  for col in range(original_shape[1]):\n",
    "    scaled_up_array[:, col] = np.interp(target_indices, original_indices, original_array[:, col])\n",
    "\n",
    "  return scaled_up_array\n",
    "\n",
    "\n",
    "session_arrays = prep_sessions(sessions, data_columns)\n",
    "normalized_session_arrays = [vertically_scale_array(s) for s in session_arrays]\n",
    "labels, labels_key = generate_labels_from_sessions(sessions)\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 20.2092 - accuracy: 0.1923 - val_loss: 2.7273 - val_accuracy: 0.7143\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.4941 - accuracy: 0.6923 - val_loss: 2.5269 - val_accuracy: 0.8571\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7674 - accuracy: 0.8462 - val_loss: 2.9105 - val_accuracy: 0.8571\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5786 - accuracy: 0.9231 - val_loss: 3.0485 - val_accuracy: 0.8571\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0902 - accuracy: 0.9615 - val_loss: 3.1579 - val_accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.9556e-04 - accuracy: 1.0000 - val_loss: 3.2420 - val_accuracy: 0.8571\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.3579e-04 - accuracy: 1.0000 - val_loss: 3.3153 - val_accuracy: 0.8571\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.2826e-04 - accuracy: 1.0000 - val_loss: 3.3798 - val_accuracy: 0.8571\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6630e-04 - accuracy: 1.0000 - val_loss: 3.4404 - val_accuracy: 0.8571\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.8841e-04 - accuracy: 1.0000 - val_loss: 3.4985 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x13e174610>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Stack the arrays\n",
    "data = np.stack(normalized_session_arrays)  # 33 arrays of shape (200, 6)\n",
    "labels = np.array(labels)  # 33 labels\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(layers.Input(shape=(200, 6)))  # Input layer\n",
    "\n",
    "# Add some layers (adjust as needed)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(len(np.unique(labels)), activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "category = to_categorical(labels, num_classes=np.max(labels)+1)\n",
    "model.fit(data, category, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shoot In 93 93\n",
      "Shoot In 89 89\n",
      "Shoot In 99 99\n"
     ]
    }
   ],
   "source": [
    "db = Prisma()\n",
    "db.connect()\n",
    "\n",
    "sessions = db.session.find_many(\n",
    "  where={\n",
    "    'moveId': 'cllpzabyd0000m35m17byo2dp'\n",
    "  },\n",
    "  include={\n",
    "    'move':True\n",
    "  }\n",
    ")\n",
    "sessions[:] = [i for i in sessions if len(i.dict()['accelerationX']) == len(i.dict()['gyroX'])]\n",
    "len(sessions)\n",
    "for s in sessions:\n",
    "  print(s.dict()['move']['name'], len(s.dict()['gyroX']), len(s.dict()['accelerationX']))\n",
    "\n",
    "\n",
    "db.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Down Up': 0, 'Square': 1, 'Circle': 2, 'Up Down': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[153.58553 , -48.847153, -45.16167 , -60.9632  ]], dtype=float32)>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_arrays = prep_sessions(sessions, data_columns)\n",
    "normalized_session_arrays_test = [vertically_scale_array(s) for s in session_arrays]\n",
    "print(labels_key)\n",
    "model(np.array([normalized_session_arrays_test[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
